{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6472152",
   "metadata": {},
   "source": [
    "# Weather Prediction Model Training\n",
    "\n",
    "This notebook trains an LSTM (Long Short-Term Memory) neural network to predict weather conditions based on historical data. The model will be deployed to an edge device for real-time weather forecasting.\n",
    "\n",
    "## Model Overview\n",
    "- **Input**: Historical weather data (30-day lookback)\n",
    "- **Features**: Precipitation, Average Temperature, Max Temperature, Min Temperature, Seasonal patterns\n",
    "- **Output**: Next day weather predictions\n",
    "- **Model**: LSTM with TensorFlow Lite optimization for edge deployment\n",
    "\n",
    "## Steps:\n",
    "1. Data Loading and Preprocessing\n",
    "2. Feature Engineering \n",
    "3. Model Architecture Design\n",
    "4. Training and Validation\n",
    "5. Model Evaluation\n",
    "6. TensorFlow Lite Conversion\n",
    "7. Model Export for Edge Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa5e7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from ../datasets/weather.csv\n",
      "Dataset shape: (17247, 6)\n",
      "Date range: 1975-01-01 to 2025-01-26\n",
      "Columns: ['STATION', 'NAME', 'PRCP', 'TAVG', 'TMAX', 'TMIN']\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Initial Exploration\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Check if dataset exists\n",
    "dataset_path = '../datasets/weather.csv'\n",
    "if not os.path.exists(dataset_path):\n",
    "    print(f\"Dataset not found at {dataset_path}\")\n",
    "    print(\"Please ensure the weather.csv file is in the datasets folder\")\n",
    "else:\n",
    "    print(f\"Loading dataset from {dataset_path}\")\n",
    "    weather = pd.read_csv(dataset_path, index_col=\"DATE\")\n",
    "    print(f\"Dataset shape: {weather.shape}\")\n",
    "    print(f\"Date range: {weather.index.min()} to {weather.index.max()}\")\n",
    "    print(f\"Columns: {list(weather.columns)}\")\n",
    "    weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fd0761e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing data quality...\n",
      "\n",
      "üìä Missing Data Percentage:\n",
      "  STATION: ‚úÖ No missing data\n",
      "  NAME: ‚úÖ No missing data\n",
      "  PRCP: 51.80%\n",
      "  TAVG: 3.60%\n",
      "  TMAX: 25.85%\n",
      "  TMIN: 24.76%\n",
      "\n",
      "üìà Total records: 17,247\n",
      "üìÖ Years of data: 50.1\n",
      "\n",
      "üìä Data Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TAVG</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8313.000000</td>\n",
       "      <td>16626.000000</td>\n",
       "      <td>12789.000000</td>\n",
       "      <td>12976.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.833694</td>\n",
       "      <td>19.083586</td>\n",
       "      <td>25.686066</td>\n",
       "      <td>12.890436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>10.757854</td>\n",
       "      <td>3.406852</td>\n",
       "      <td>3.447130</td>\n",
       "      <td>3.956947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.300000</td>\n",
       "      <td>11.500000</td>\n",
       "      <td>-2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>23.400000</td>\n",
       "      <td>9.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.700000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>13.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>16.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>176.000000</td>\n",
       "      <td>29.600000</td>\n",
       "      <td>36.700000</td>\n",
       "      <td>21.600000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              PRCP          TAVG          TMAX          TMIN\n",
       "count  8313.000000  16626.000000  12789.000000  12976.000000\n",
       "mean      3.833694     19.083586     25.686066     12.890436\n",
       "std      10.757854      3.406852      3.447130      3.956947\n",
       "min       0.000000      6.300000     11.500000     -2.600000\n",
       "25%       0.000000     16.700000     23.400000      9.700000\n",
       "50%       0.000000     19.700000     26.000000     13.700000\n",
       "75%       2.000000     21.500000     28.100000     16.300000\n",
       "max     176.000000     29.600000     36.700000     21.600000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Quality Analysis\n",
    "print(\"üîç Analyzing data quality...\")\n",
    "print(\"\\nüìä Missing Data Percentage:\")\n",
    "null_pct = weather.apply(pd.isnull).sum() / len(weather) * 100\n",
    "for col, pct in null_pct.items():\n",
    "    if pct > 0:\n",
    "        print(f\"  {col}: {pct:.2f}%\")\n",
    "    else:\n",
    "        print(f\"  {col}: ‚úÖ No missing data\")\n",
    "\n",
    "print(f\"\\nüìà Total records: {len(weather):,}\")\n",
    "\n",
    "# Convert index to datetime if it's not already\n",
    "if not isinstance(weather.index, pd.DatetimeIndex):\n",
    "    weather.index = pd.to_datetime(weather.index)\n",
    "\n",
    "print(f\"üìÖ Years of data: {(weather.index.max() - weather.index.min()).days / 365.25:.1f}\")\n",
    "\n",
    "# Display basic statistics\n",
    "print(\"\\nüìä Data Summary:\")\n",
    "weather.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fbf6f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>name</th>\n",
       "      <th>prcp</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1975-01-01</th>\n",
       "      <td>ZI000067775</td>\n",
       "      <td>HARARE KUTSAGA, ZI</td>\n",
       "      <td>0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.5</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975-01-02</th>\n",
       "      <td>ZI000067775</td>\n",
       "      <td>HARARE KUTSAGA, ZI</td>\n",
       "      <td>9.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975-01-03</th>\n",
       "      <td>ZI000067775</td>\n",
       "      <td>HARARE KUTSAGA, ZI</td>\n",
       "      <td>43.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.5</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975-01-04</th>\n",
       "      <td>ZI000067775</td>\n",
       "      <td>HARARE KUTSAGA, ZI</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.2</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975-01-05</th>\n",
       "      <td>ZI000067775</td>\n",
       "      <td>HARARE KUTSAGA, ZI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.1</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-22</th>\n",
       "      <td>ZI000067775</td>\n",
       "      <td>HARARE KUTSAGA, ZI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-23</th>\n",
       "      <td>ZI000067775</td>\n",
       "      <td>HARARE KUTSAGA, ZI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>26.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-24</th>\n",
       "      <td>ZI000067775</td>\n",
       "      <td>HARARE KUTSAGA, ZI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-25</th>\n",
       "      <td>ZI000067775</td>\n",
       "      <td>HARARE KUTSAGA, ZI</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-01-26</th>\n",
       "      <td>ZI000067775</td>\n",
       "      <td>HARARE KUTSAGA, ZI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.3</td>\n",
       "      <td>26.2</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17247 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                station                name  prcp  tavg  tmax  tmin\n",
       "DATE                                                               \n",
       "1975-01-01  ZI000067775  HARARE KUTSAGA, ZI   0.5   NaN  24.5  15.5\n",
       "1975-01-02  ZI000067775  HARARE KUTSAGA, ZI   9.9   NaN  28.0  15.5\n",
       "1975-01-03  ZI000067775  HARARE KUTSAGA, ZI  43.2   NaN  23.5  15.8\n",
       "1975-01-04  ZI000067775  HARARE KUTSAGA, ZI   0.6   NaN  23.2  15.5\n",
       "1975-01-05  ZI000067775  HARARE KUTSAGA, ZI   0.0   NaN  24.1  13.6\n",
       "...                 ...                 ...   ...   ...   ...   ...\n",
       "2025-01-22  ZI000067775  HARARE KUTSAGA, ZI   1.0  20.6   NaN  16.6\n",
       "2025-01-23  ZI000067775  HARARE KUTSAGA, ZI   0.0  21.9  26.2   NaN\n",
       "2025-01-24  ZI000067775  HARARE KUTSAGA, ZI   NaN  21.1  25.1  16.6\n",
       "2025-01-25  ZI000067775  HARARE KUTSAGA, ZI   NaN  21.4   NaN   NaN\n",
       "2025-01-26  ZI000067775  HARARE KUTSAGA, ZI   0.0  20.3  26.2  17.5\n",
       "\n",
       "[17247 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.columns = weather.columns.str.lower()\n",
    "weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "527d4a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station    0.000000\n",
       "name       0.000000\n",
       "prcp       0.000000\n",
       "tavg       0.162347\n",
       "tmax       0.000000\n",
       "tmin       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = weather.ffill()\n",
    "weather.apply(pd.isnull).sum() / len(weather) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8ec359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal with 0.16% null values in tavg\n",
    "weather['tavg'] = weather['tavg'].fillna(weather['tavg'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83df8e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "station    0.0\n",
       "name       0.0\n",
       "prcp       0.0\n",
       "tavg       0.0\n",
       "tmax       0.0\n",
       "tmin       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.apply(pd.isnull).sum() / len(weather) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce5b81b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.index = pd.to_datetime(weather.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97d1208a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>prcp</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmax</th>\n",
       "      <th>tmin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1975-01-01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>19.049364</td>\n",
       "      <td>24.5</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1975-01-02</td>\n",
       "      <td>9.9</td>\n",
       "      <td>19.049364</td>\n",
       "      <td>28.0</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1975-01-03</td>\n",
       "      <td>43.2</td>\n",
       "      <td>19.049364</td>\n",
       "      <td>23.5</td>\n",
       "      <td>15.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1975-01-04</td>\n",
       "      <td>0.6</td>\n",
       "      <td>19.049364</td>\n",
       "      <td>23.2</td>\n",
       "      <td>15.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1975-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.049364</td>\n",
       "      <td>24.1</td>\n",
       "      <td>13.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17242</th>\n",
       "      <td>2025-01-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.600000</td>\n",
       "      <td>24.1</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17243</th>\n",
       "      <td>2025-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.900000</td>\n",
       "      <td>26.2</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17244</th>\n",
       "      <td>2025-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.100000</td>\n",
       "      <td>25.1</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17245</th>\n",
       "      <td>2025-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.400000</td>\n",
       "      <td>25.1</td>\n",
       "      <td>16.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17246</th>\n",
       "      <td>2025-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.300000</td>\n",
       "      <td>26.2</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17247 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  prcp       tavg  tmax  tmin\n",
       "0     1975-01-01   0.5  19.049364  24.5  15.5\n",
       "1     1975-01-02   9.9  19.049364  28.0  15.5\n",
       "2     1975-01-03  43.2  19.049364  23.5  15.8\n",
       "3     1975-01-04   0.6  19.049364  23.2  15.5\n",
       "4     1975-01-05   0.0  19.049364  24.1  13.6\n",
       "...          ...   ...        ...   ...   ...\n",
       "17242 2025-01-22   1.0  20.600000  24.1  16.6\n",
       "17243 2025-01-23   0.0  21.900000  26.2  16.6\n",
       "17244 2025-01-24   0.0  21.100000  25.1  16.6\n",
       "17245 2025-01-25   0.0  21.400000  25.1  16.6\n",
       "17246 2025-01-26   0.0  20.300000  26.2  17.5\n",
       "\n",
       "[17247 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "# Load daily data (columns: date, prcp, tavg, tmax, tmin)\n",
    "data = weather.reset_index()\n",
    "data.columns = data.columns.str.lower()\n",
    "data = data[['date', 'prcp', 'tavg', 'tmax', 'tmin']]\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "058e9dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add temporal features (critical for daily data!)\n",
    "data['day_of_year_sin'] = np.sin(2 * np.pi * data['date'].dt.dayofyear / 365)\n",
    "data['day_of_year_cos'] = np.cos(2 * np.pi * data['date'].dt.dayofyear / 365)\n",
    "\n",
    "# Target: Predict next day's prcp, tavg, tmax, tmin\n",
    "target_cols = ['prcp', 'tavg', 'tmax', 'tmin']\n",
    "features = ['prcp', 'tavg', 'tmax', 'tmin', 'day_of_year_sin', 'day_of_year_cos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ee8220d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_params.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalization\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(data[features])\n",
    "joblib.dump(scaler, 'scaler_params.joblib')  # Save for Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bddb8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (17216, 30, 6), Target shape: (17216, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "def create_daily_dataset(data, lookback=30, forecast=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data)-lookback-forecast):\n",
    "        X.append(data[i:i+lookback])\n",
    "        Y.append(data[i+lookback:i+lookback+forecast, :4])  # All 4 targets\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "X, Y = create_daily_dataset(scaled)\n",
    "print(f\"Input shape: {X.shape}, Target shape: {Y.shape}\")  # (n_samples, 30, 6), (n_samples, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bddcd8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 23:50:02.303382: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-01 23:50:02.376339: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-01 23:50:02.377374: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-01 23:50:03.510593: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-07-01 23:50:03.510593: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Building Enhanced LSTM Model...\n",
      "‚úÖ Model compiled successfully!\n",
      "\n",
      "üèóÔ∏è Model Architecture:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 30, 64)            18176     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 30, 64)            256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 64)            0         \n",
      "‚úÖ Model compiled successfully!\n",
      "\n",
      "üèóÔ∏è Model Architecture:\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_1 (LSTM)               (None, 30, 64)            18176     \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 30, 64)            256       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30, 64)            0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 32)                128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      " dropout_1 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31572 (123.33 KB)\n",
      "Trainable params: 31380 (122.58 KB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "Total params: 31572 (123.33 KB)\n",
      "Trainable params: 31380 (122.58 KB)\n",
      "Non-trainable params: 192 (768.00 Byte)\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Enhanced LSTM Model Architecture\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(\"üß† Building Enhanced LSTM Model...\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "model = Sequential([\n",
    "    # First LSTM layer with return sequences\n",
    "    LSTM(64, return_sequences=True, input_shape=(30, 6), name='lstm_1'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Second LSTM layer\n",
    "    LSTM(32, return_sequences=False, name='lstm_2'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    # Dense layers for predictions\n",
    "    Dense(16, activation='relu', name='dense_1'),\n",
    "    Dropout(0.1),\n",
    "    Dense(4, name='output')  # Predicts prcp, tavg, tmax, tmin for next day\n",
    "])\n",
    "\n",
    "# Compile with custom optimizer\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(\n",
    "    loss='mse', \n",
    "    optimizer=optimizer,\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Model compiled successfully!\")\n",
    "print(\"\\nüèóÔ∏è Model Architecture:\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a511b81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting model training...\n",
      "Epoch 1/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.1940 - mae: 0.3204\n",
      "Epoch 1: val_loss improved from inf to 0.05250, saving model to best_weather_model.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.05250, saving model to best_weather_model.h5\n",
      "431/431 [==============================] - 20s 35ms/step - loss: 0.1939 - mae: 0.3203 - val_loss: 0.0525 - val_mae: 0.1992 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "431/431 [==============================] - 20s 35ms/step - loss: 0.1939 - mae: 0.3203 - val_loss: 0.0525 - val_mae: 0.1992 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "  3/431 [..............................] - ETA: 17s - loss: 0.0630 - mae: 0.1940"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tauya/Desktop/Project Final/.venv/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "430/431 [============================>.] - ETA: 0s - loss: 0.0447 - mae: 0.1649\n",
      "Epoch 2: val_loss improved from 0.05250 to 0.02430, saving model to best_weather_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.05250 to 0.02430, saving model to best_weather_model.h5\n",
      "431/431 [==============================] - 14s 32ms/step - loss: 0.0447 - mae: 0.1648 - val_loss: 0.0243 - val_mae: 0.1317 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "431/431 [==============================] - 14s 32ms/step - loss: 0.0447 - mae: 0.1648 - val_loss: 0.0243 - val_mae: 0.1317 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0277 - mae: 0.1302\n",
      "Epoch 3: val_loss improved from 0.02430 to 0.01989, saving model to best_weather_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.02430 to 0.01989, saving model to best_weather_model.h5\n",
      "431/431 [==============================] - 14s 32ms/step - loss: 0.0277 - mae: 0.1301 - val_loss: 0.0199 - val_mae: 0.1143 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "431/431 [==============================] - 14s 32ms/step - loss: 0.0277 - mae: 0.1301 - val_loss: 0.0199 - val_mae: 0.1143 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0215 - mae: 0.1141\n",
      "Epoch 4: val_loss improved from 0.01989 to 0.01889, saving model to best_weather_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.01989 to 0.01889, saving model to best_weather_model.h5\n",
      "431/431 [==============================] - 13s 31ms/step - loss: 0.0215 - mae: 0.1141 - val_loss: 0.0189 - val_mae: 0.1086 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "431/431 [==============================] - 13s 31ms/step - loss: 0.0215 - mae: 0.1141 - val_loss: 0.0189 - val_mae: 0.1086 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0190 - mae: 0.1057\n",
      "Epoch 5: val_loss did not improve from 0.01889\n",
      "431/431 [==============================] - 13s 31ms/step - loss: 0.0190 - mae: 0.1057 - val_loss: 0.0192 - val_mae: 0.1072 - lr: 0.0010\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.01889\n",
      "431/431 [==============================] - 13s 31ms/step - loss: 0.0190 - mae: 0.1057 - val_loss: 0.0192 - val_mae: 0.1072 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "Epoch 6/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0178 - mae: 0.1014\n",
      "Epoch 6: val_loss improved from 0.01889 to 0.01856, saving model to best_weather_model.h5\n",
      "\n",
      "Epoch 6: val_loss improved from 0.01889 to 0.01856, saving model to best_weather_model.h5\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0178 - mae: 0.1014 - val_loss: 0.0186 - val_mae: 0.1024 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0178 - mae: 0.1014 - val_loss: 0.0186 - val_mae: 0.1024 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0172 - mae: 0.0986\n",
      "Epoch 7: val_loss improved from 0.01856 to 0.01814, saving model to best_weather_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.01856 to 0.01814, saving model to best_weather_model.h5\n",
      "431/431 [==============================] - 14s 32ms/step - loss: 0.0172 - mae: 0.0986 - val_loss: 0.0181 - val_mae: 0.1001 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "431/431 [==============================] - 14s 32ms/step - loss: 0.0172 - mae: 0.0986 - val_loss: 0.0181 - val_mae: 0.1001 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0169 - mae: 0.0973\n",
      "Epoch 8: val_loss did not improve from 0.01814\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0169 - mae: 0.0973 - val_loss: 0.0184 - val_mae: 0.0998 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.01814\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0169 - mae: 0.0973 - val_loss: 0.0184 - val_mae: 0.0998 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0168 - mae: 0.0964\n",
      "Epoch 9: val_loss improved from 0.01814 to 0.01806, saving model to best_weather_model.h5\n",
      "\n",
      "Epoch 9: val_loss improved from 0.01814 to 0.01806, saving model to best_weather_model.h5\n",
      "431/431 [==============================] - 16s 37ms/step - loss: 0.0168 - mae: 0.0964 - val_loss: 0.0181 - val_mae: 0.0981 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "431/431 [==============================] - 16s 37ms/step - loss: 0.0168 - mae: 0.0964 - val_loss: 0.0181 - val_mae: 0.0981 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0168 - mae: 0.0961\n",
      "Epoch 10: val_loss improved from 0.01806 to 0.01800, saving model to best_weather_model.h5\n",
      "\n",
      "Epoch 10: val_loss improved from 0.01806 to 0.01800, saving model to best_weather_model.h5\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0167 - mae: 0.0961 - val_loss: 0.0180 - val_mae: 0.0974 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0167 - mae: 0.0961 - val_loss: 0.0180 - val_mae: 0.0974 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0958\n",
      "Epoch 11: val_loss did not improve from 0.01800\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0167 - mae: 0.0958 - val_loss: 0.0181 - val_mae: 0.0986 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.01800\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0167 - mae: 0.0958 - val_loss: 0.0181 - val_mae: 0.0986 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0956\n",
      "Epoch 12: val_loss did not improve from 0.01800\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0167 - mae: 0.0956 - val_loss: 0.0181 - val_mae: 0.0984 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.01800\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0167 - mae: 0.0956 - val_loss: 0.0181 - val_mae: 0.0984 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0956\n",
      "Epoch 13: val_loss did not improve from 0.01800\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0167 - mae: 0.0956 - val_loss: 0.0181 - val_mae: 0.0975 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.01800\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0167 - mae: 0.0956 - val_loss: 0.0181 - val_mae: 0.0975 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0956\n",
      "Epoch 14: val_loss did not improve from 0.01800\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0167 - mae: 0.0956 - val_loss: 0.0181 - val_mae: 0.0973 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.01800\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0167 - mae: 0.0956 - val_loss: 0.0181 - val_mae: 0.0973 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0167 - mae: 0.0955\n",
      "Epoch 15: val_loss did not improve from 0.01800\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0167 - mae: 0.0955 - val_loss: 0.0181 - val_mae: 0.0977 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.01800\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0167 - mae: 0.0955 - val_loss: 0.0181 - val_mae: 0.0977 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0167 - mae: 0.0955\n",
      "Epoch 16: val_loss improved from 0.01800 to 0.01777, saving model to best_weather_model.h5\n",
      "\n",
      "Epoch 16: val_loss improved from 0.01800 to 0.01777, saving model to best_weather_model.h5\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0167 - mae: 0.0955 - val_loss: 0.0178 - val_mae: 0.0982 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0167 - mae: 0.0955 - val_loss: 0.0178 - val_mae: 0.0982 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0955\n",
      "Epoch 17: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0167 - mae: 0.0955 - val_loss: 0.0179 - val_mae: 0.0970 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0167 - mae: 0.0955 - val_loss: 0.0179 - val_mae: 0.0970 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0167 - mae: 0.0955\n",
      "Epoch 18: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0167 - mae: 0.0955 - val_loss: 0.0179 - val_mae: 0.0966 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0167 - mae: 0.0955 - val_loss: 0.0179 - val_mae: 0.0966 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0166 - mae: 0.0954\n",
      "Epoch 19: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0166 - mae: 0.0954 - val_loss: 0.0180 - val_mae: 0.0969 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0166 - mae: 0.0954 - val_loss: 0.0180 - val_mae: 0.0969 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0954\n",
      "Epoch 20: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0166 - mae: 0.0954 - val_loss: 0.0180 - val_mae: 0.0974 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0166 - mae: 0.0954 - val_loss: 0.0180 - val_mae: 0.0974 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0166 - mae: 0.0953\n",
      "Epoch 21: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0166 - mae: 0.0953 - val_loss: 0.0182 - val_mae: 0.0984 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0166 - mae: 0.0953 - val_loss: 0.0182 - val_mae: 0.0984 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0953\n",
      "Epoch 22: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0166 - mae: 0.0953 - val_loss: 0.0180 - val_mae: 0.0971 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0166 - mae: 0.0953 - val_loss: 0.0180 - val_mae: 0.0971 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0166 - mae: 0.0951\n",
      "Epoch 23: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0166 - mae: 0.0951 - val_loss: 0.0183 - val_mae: 0.0983 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.01777\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0166 - mae: 0.0951 - val_loss: 0.0183 - val_mae: 0.0983 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0166 - mae: 0.0952\n",
      "Epoch 24: val_loss improved from 0.01777 to 0.01774, saving model to best_weather_model.h5\n",
      "\n",
      "Epoch 24: val_loss improved from 0.01777 to 0.01774, saving model to best_weather_model.h5\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0166 - mae: 0.0952 - val_loss: 0.0177 - val_mae: 0.0973 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0166 - mae: 0.0952 - val_loss: 0.0177 - val_mae: 0.0973 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0166 - mae: 0.0950\n",
      "Epoch 25: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0166 - mae: 0.0950 - val_loss: 0.0179 - val_mae: 0.0971 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0166 - mae: 0.0950 - val_loss: 0.0179 - val_mae: 0.0971 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0950\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0950 - val_loss: 0.0180 - val_mae: 0.0990 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0950 - val_loss: 0.0180 - val_mae: 0.0990 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0165 - mae: 0.0950\n",
      "Epoch 27: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 16s 37ms/step - loss: 0.0165 - mae: 0.0950 - val_loss: 0.0182 - val_mae: 0.0982 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\n",
      "Epoch 27: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 16s 37ms/step - loss: 0.0165 - mae: 0.0950 - val_loss: 0.0182 - val_mae: 0.0982 - lr: 5.0000e-04\n",
      "Epoch 28/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0165 - mae: 0.0949\n",
      "Epoch 28: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0185 - val_mae: 0.0996 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0185 - val_mae: 0.0996 - lr: 5.0000e-04\n",
      "Epoch 29/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0949\n",
      "Epoch 29: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0180 - val_mae: 0.0974 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 34ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0180 - val_mae: 0.0974 - lr: 5.0000e-04\n",
      "Epoch 30/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0949\n",
      "Epoch 30: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0184 - val_mae: 0.0987 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0184 - val_mae: 0.0987 - lr: 5.0000e-04\n",
      "Epoch 31/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0949\n",
      "Epoch 31: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0184 - val_mae: 0.0984 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0184 - val_mae: 0.0984 - lr: 5.0000e-04\n",
      "Epoch 32/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0947\n",
      "Epoch 32: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0947 - val_loss: 0.0185 - val_mae: 0.0993 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0947 - val_loss: 0.0185 - val_mae: 0.0993 - lr: 5.0000e-04\n",
      "Epoch 33/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0165 - mae: 0.0949\n",
      "Epoch 33: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0184 - val_mae: 0.0992 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0184 - val_mae: 0.0992 - lr: 5.0000e-04\n",
      "Epoch 34/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0949\n",
      "Epoch 34: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0185 - val_mae: 0.0988 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0949 - val_loss: 0.0185 - val_mae: 0.0988 - lr: 5.0000e-04\n",
      "Epoch 35/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0947\n",
      "Epoch 35: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0947 - val_loss: 0.0190 - val_mae: 0.1002 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 15s 35ms/step - loss: 0.0165 - mae: 0.0947 - val_loss: 0.0190 - val_mae: 0.1002 - lr: 5.0000e-04\n",
      "Epoch 36/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0165 - mae: 0.0948\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 16s 37ms/step - loss: 0.0165 - mae: 0.0948 - val_loss: 0.0187 - val_mae: 0.0996 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 16s 37ms/step - loss: 0.0165 - mae: 0.0948 - val_loss: 0.0187 - val_mae: 0.0996 - lr: 5.0000e-04\n",
      "Epoch 37/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0946\n",
      "Epoch 37: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 16s 36ms/step - loss: 0.0165 - mae: 0.0946 - val_loss: 0.0184 - val_mae: 0.0988 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 16s 36ms/step - loss: 0.0165 - mae: 0.0946 - val_loss: 0.0184 - val_mae: 0.0988 - lr: 2.5000e-04\n",
      "Epoch 38/100\n",
      "431/431 [==============================] - ETA: 0s - loss: 0.0165 - mae: 0.0947\n",
      "Epoch 38: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 16s 36ms/step - loss: 0.0165 - mae: 0.0947 - val_loss: 0.0184 - val_mae: 0.0983 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 16s 36ms/step - loss: 0.0165 - mae: 0.0947 - val_loss: 0.0184 - val_mae: 0.0983 - lr: 2.5000e-04\n",
      "Epoch 39/100\n",
      "430/431 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0948Restoring model weights from the end of the best epoch: 24.\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 18s 42ms/step - loss: 0.0165 - mae: 0.0948 - val_loss: 0.0183 - val_mae: 0.0986 - lr: 2.5000e-04\n",
      "Epoch 39: early stopping\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.01774\n",
      "431/431 [==============================] - 18s 42ms/step - loss: 0.0165 - mae: 0.0948 - val_loss: 0.0183 - val_mae: 0.0986 - lr: 2.5000e-04\n",
      "Epoch 39: early stopping\n",
      "‚úÖ Training completed!\n",
      "‚úÖ Training completed!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Final Training Loss: 0.0165\n",
      "üìä Final Validation Loss: 0.0183\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"üöÄ Starting model training...\")\n",
    "\n",
    "# Enhanced callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=15,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        min_lr=1e-6,\n",
    "        verbose=1\n",
    "    ),\n",
    "    ModelCheckpoint(\n",
    "        'best_weather_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X, Y, \n",
    "    epochs=100, \n",
    "    batch_size=32,  # Increased batch size for better training\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Training completed!\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"üìä Final Training Loss: {history.history['loss'][-1]:.4f}\")\n",
    "print(f\"üìä Final Validation Loss: {history.history['val_loss'][-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b21ade1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Converting to TensorFlow Lite...\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplh8xteb5/assets\n",
      "INFO:tensorflow:Assets written to: /tmp/tmplh8xteb5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmplh8xteb5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorFlow Lite conversion successful!\n",
      "üì¶ Model size: 52.8 KB\n",
      "\n",
      "üß™ Testing TensorFlow Lite Model:\n",
      "Input shape: [ 1 30  6]\n",
      "Output shape: [1 4]\n",
      "‚úÖ TFLite model test successful!\n",
      "Test output shape: (1, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-02 00:02:42.015513: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:364] Ignored output_format.\n",
      "2025-07-02 00:02:42.015556: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:367] Ignored drop_control_dependency.\n",
      "2025-07-02 00:02:42.015920: I tensorflow/cc/saved_model/reader.cc:45] Reading SavedModel from: /tmp/tmplh8xteb5\n",
      "2025-07-02 00:02:42.036962: I tensorflow/cc/saved_model/reader.cc:91] Reading meta graph with tags { serve }\n",
      "2025-07-02 00:02:42.037004: I tensorflow/cc/saved_model/reader.cc:132] Reading SavedModel debug info (if present) from: /tmp/tmplh8xteb5\n",
      "2025-07-02 00:02:42.110294: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:375] MLIR V1 optimization pass is not enabled\n",
      "2025-07-02 00:02:42.132812: I tensorflow/cc/saved_model/loader.cc:231] Restoring SavedModel bundle.\n",
      "2025-07-02 00:02:42.401555: I tensorflow/cc/saved_model/loader.cc:215] Running initialization op on SavedModel bundle at path: /tmp/tmplh8xteb5\n",
      "2025-07-02 00:02:42.539927: I tensorflow/cc/saved_model/loader.cc:314] SavedModel load for tags { serve }; Status: success: OK. Took 524011 microseconds.\n",
      "2025-07-02 00:02:42.695653: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-07-02 00:02:43.035036: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2073] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
      "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x32xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x32xf32>>>, tensor<i32>, tensor<?x32xf32>) -> (tensor<!tf_type.variant<tensor<?x32xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<i32>, tensor<?x64xf32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x32xf32>>>, tensor<2xi32>) -> (tensor<1x?x32xf32>) : {device = \"\", num_elements = 1 : i64}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<2xi32>) -> (tensor<?x?x64xf32>) : {device = \"\", num_elements = -1 : i64}\n",
      "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n",
      "INFO: Created TensorFlow Lite delegate for select TF ops.\n",
      "INFO: TfLiteFlexDelegate delegate: 4 nodes delegated out of 24 nodes with 3 partitions.\n",
      "\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Lite Model Conversion and Optimization\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print(\"üîÑ Converting to TensorFlow Lite...\")\n",
    "\n",
    "# Convert to TensorFlow Lite with optimizations\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "\n",
    "# Apply optimizations for edge deployment\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [\n",
    "    tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "    tf.lite.OpsSet.SELECT_TF_OPS\n",
    "]\n",
    "\n",
    "# Critical for LSTM models on edge devices\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "converter.experimental_enable_resource_variables = True\n",
    "\n",
    "# Convert the model\n",
    "try:\n",
    "    tflite_model = converter.convert()\n",
    "    print(\"‚úÖ TensorFlow Lite conversion successful!\")\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = 'weather_prediction_model.tflite'\n",
    "    with open(model_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    \n",
    "    # Check model size\n",
    "    model_size = os.path.getsize(model_path) / 1024  # Size in KB\n",
    "    print(f\"üì¶ Model size: {model_size:.1f} KB\")\n",
    "    \n",
    "    # Test the TFLite model\n",
    "    print(\"\\nüß™ Testing TensorFlow Lite Model:\")\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    \n",
    "    # Get input and output details\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    print(f\"Input shape: {input_details[0]['shape']}\")\n",
    "    print(f\"Output shape: {output_details[0]['shape']}\")\n",
    "    \n",
    "    # Test with sample data\n",
    "    test_input = np.random.random((1, 30, 6)).astype(np.float32)\n",
    "    interpreter.set_tensor(input_details[0]['index'], test_input)\n",
    "    interpreter.invoke()\n",
    "    output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "    \n",
    "    print(f\"‚úÖ TFLite model test successful!\")\n",
    "    print(f\"Test output shape: {output_data.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Conversion failed: {e}\")\n",
    "    print(\"Trying alternative conversion...\")\n",
    "    \n",
    "    # Alternative conversion without some optimizations\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.target_spec.supported_ops = [\n",
    "        tf.lite.OpsSet.TFLITE_BUILTINS,\n",
    "        tf.lite.OpsSet.SELECT_TF_OPS\n",
    "    ]\n",
    "    tflite_model = converter.convert()\n",
    "    \n",
    "    with open('weather_prediction_model_basic.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(\"‚úÖ Basic TensorFlow Lite conversion successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9666dbc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Model Evaluation Results:\n",
      "==================================================\n",
      "108/108 [==============================] - 3s 12ms/step\n",
      "108/108 [==============================] - 3s 12ms/step\n",
      "\n",
      "Precipitation:\n",
      "  MAE:  0.0194\n",
      "  RMSE: 0.0372\n",
      "  R¬≤:   -0.0655\n",
      "\n",
      "Avg Temp:\n",
      "  MAE:  0.1291\n",
      "  RMSE: 0.1561\n",
      "  R¬≤:   0.0003\n",
      "\n",
      "Max Temp:\n",
      "  MAE:  0.1217\n",
      "  RMSE: 0.1430\n",
      "  R¬≤:   -0.1320\n",
      "\n",
      "Min Temp:\n",
      "  MAE:  0.1190\n",
      "  RMSE: 0.1573\n",
      "  R¬≤:   0.0021\n",
      "\n",
      "üîß Scaler Parameters for Edge Deployment:\n",
      "==================================================\n",
      "Scale values: [0.005681818181818182, 0.04291845493562232, 0.03968253968253968, 0.04132231404958677, 0.5000046301747816, 0.5000092603924402]\n",
      "Min values: [0.0, -0.27038626609442057, -0.45634920634920634, 0.10743801652892561, 0.5, 0.49999073960755985]\n",
      "\n",
      "üß™ Testing Prediction Function:\n",
      "==================================================\n",
      "Input: Prcp=10, Tavg=20, Tmax=25, Tmin=15\n",
      "Scaled input: [0.05681818 0.58798283 0.53571429 0.72727273 0.75000232 0.89999815]\n",
      "Raw prediction: [0.01579096 0.5491368  0.5673217  0.6544491 ]\n",
      "Predicted next day: Prcp=2.8, Tavg=19.1¬∞C, Tmax=25.8¬∞C, Tmin=13.2¬∞C\n",
      "\n",
      "Precipitation:\n",
      "  MAE:  0.0194\n",
      "  RMSE: 0.0372\n",
      "  R¬≤:   -0.0655\n",
      "\n",
      "Avg Temp:\n",
      "  MAE:  0.1291\n",
      "  RMSE: 0.1561\n",
      "  R¬≤:   0.0003\n",
      "\n",
      "Max Temp:\n",
      "  MAE:  0.1217\n",
      "  RMSE: 0.1430\n",
      "  R¬≤:   -0.1320\n",
      "\n",
      "Min Temp:\n",
      "  MAE:  0.1190\n",
      "  RMSE: 0.1573\n",
      "  R¬≤:   0.0021\n",
      "\n",
      "üîß Scaler Parameters for Edge Deployment:\n",
      "==================================================\n",
      "Scale values: [0.005681818181818182, 0.04291845493562232, 0.03968253968253968, 0.04132231404958677, 0.5000046301747816, 0.5000092603924402]\n",
      "Min values: [0.0, -0.27038626609442057, -0.45634920634920634, 0.10743801652892561, 0.5, 0.49999073960755985]\n",
      "\n",
      "üß™ Testing Prediction Function:\n",
      "==================================================\n",
      "Input: Prcp=10, Tavg=20, Tmax=25, Tmin=15\n",
      "Scaled input: [0.05681818 0.58798283 0.53571429 0.72727273 0.75000232 0.89999815]\n",
      "Raw prediction: [0.01579096 0.5491368  0.5673217  0.6544491 ]\n",
      "Predicted next day: Prcp=2.8, Tavg=19.1¬∞C, Tmax=25.8¬∞C, Tmin=13.2¬∞C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tauya/Desktop/Project Final/.venv/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Load the scaler you saved during training\n",
    "scaler = joblib.load('scaler_params.joblib')\n",
    "\n",
    "print(\"üìä Model Evaluation Results:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Make predictions on test set\n",
    "test_size = int(0.2 * len(X))\n",
    "X_train, X_test = X[:-test_size], X[-test_size:]\n",
    "Y_train, Y_test = Y[:-test_size], Y[-test_size:]\n",
    "\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate metrics for each target variable\n",
    "target_names = ['Precipitation', 'Avg Temp', 'Max Temp', 'Min Temp']\n",
    "for i, target in enumerate(target_names):\n",
    "    y_true = Y_test[:, 0, i]  # Actual values\n",
    "    y_pred = predictions[:, i]  # Predicted values\n",
    "    \n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  MAE:  {mae:.4f}\")\n",
    "    print(f\"  RMSE: {rmse:.4f}\")\n",
    "    print(f\"  R¬≤:   {r2:.4f}\")\n",
    "\n",
    "# Display scaler parameters for edge deployment\n",
    "print(\"\\nüîß Scaler Parameters for Edge Deployment:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Scale values:\", scaler.scale_.tolist())\n",
    "print(\"Min values:\", scaler.min_.tolist())\n",
    "\n",
    "# Test prediction function\n",
    "print(\"\\nüß™ Testing Prediction Function:\")\n",
    "print(\"=\" * 50)\n",
    "test_data = np.array([[10, 20, 25, 15, 0.5, 0.8]])  # Sample input\n",
    "scaled_test = scaler.transform(test_data)\n",
    "print(f\"Input: Prcp=10, Tavg=20, Tmax=25, Tmin=15\")\n",
    "print(f\"Scaled input: {scaled_test[0]}\")\n",
    "\n",
    "# Create a sequence for prediction (last 30 days)\n",
    "test_sequence = np.tile(scaled_test, (30, 1)).reshape(1, 30, 6)\n",
    "prediction = model.predict(test_sequence, verbose=0)\n",
    "print(f\"Raw prediction: {prediction[0]}\")\n",
    "\n",
    "# Inverse transform for actual values\n",
    "pred_with_features = np.zeros((1, 6))\n",
    "pred_with_features[0, :4] = prediction[0]\n",
    "pred_denormalized = scaler.inverse_transform(pred_with_features)[0, :4]\n",
    "print(f\"Predicted next day: Prcp={pred_denormalized[0]:.1f}, Tavg={pred_denormalized[1]:.1f}¬∞C, Tmax={pred_denormalized[2]:.1f}¬∞C, Tmin={pred_denormalized[3]:.1f}¬∞C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16507e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c0b8a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.05681818 0.58798283 0.53571429 0.10743802 0.5        0.49999074]]\n",
      "üì¶ Preparing files for edge deployment...\n",
      "‚úÖ Files created for edge deployment:\n",
      "üìÅ weather_prediction_model.tflite - Main model file\n",
      "üìÅ scaler_params.joblib - Preprocessing parameters\n",
      "üìÅ model_config.json - Deployment configuration\n",
      "üìÅ edge_predictor.py - Ready-to-use prediction class for edge devices\n",
      "\n",
      "üéØ Model Training Complete!\n",
      "==================================================\n",
      "Your weather prediction model is ready for deployment!\n",
      "Transfer these files to your edge device:\n",
      "  ‚Ä¢ weather_prediction_model.tflite\n",
      "  ‚Ä¢ model_config.json\n",
      "  ‚Ä¢ edge_predictor.py\n",
      "\n",
      "The model can predict tomorrow's weather based on the last 30 days of data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tauya/Desktop/Project Final/.venv/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# In your training environment\n",
    "test_data = np.array([[10, 20, 25, 0, 0, 0]])  # Sample [prcp, tavg, tmax, tmin, time_sin, time_cos]\n",
    "print(scaler.transform(test_data))\n",
    "\n",
    "# Edge Deployment Preparation\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"üì¶ Preparing files for edge deployment...\")\n",
    "\n",
    "# Create deployment configuration\n",
    "deployment_config = {\n",
    "    \"model_info\": {\n",
    "        \"name\": \"weather_prediction_lstm\",\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"input_shape\": [1, 30, 6],\n",
    "        \"output_shape\": [1, 4],\n",
    "        \"features\": [\"precipitation\", \"avg_temp\", \"max_temp\", \"min_temp\", \"day_sin\", \"day_cos\"],\n",
    "        \"targets\": [\"next_precipitation\", \"next_avg_temp\", \"next_max_temp\", \"next_min_temp\"]\n",
    "    },\n",
    "    \"preprocessing\": {\n",
    "        \"lookback_days\": 30,\n",
    "        \"scale_values\": scaler.scale_.tolist(),\n",
    "        \"min_values\": scaler.min_.tolist(),\n",
    "        \"feature_names\": [\"prcp\", \"tavg\", \"tmax\", \"tmin\", \"day_of_year_sin\", \"day_of_year_cos\"]\n",
    "    },\n",
    "    \"performance\": {\n",
    "        \"training_loss\": float(history.history['loss'][-1]),\n",
    "        \"validation_loss\": float(history.history['val_loss'][-1]),\n",
    "        \"model_size_kb\": os.path.getsize('weather_prediction_model.tflite') / 1024\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save configuration\n",
    "with open('model_config.json', 'w') as f:\n",
    "    json.dump(deployment_config, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Files created for edge deployment:\")\n",
    "print(\"üìÅ weather_prediction_model.tflite - Main model file\")\n",
    "print(\"üìÅ scaler_params.joblib - Preprocessing parameters\")\n",
    "print(\"üìÅ model_config.json - Deployment configuration\")\n",
    "\n",
    "# Create a simple prediction function for edge devices\n",
    "edge_prediction_code = '''\n",
    "# Edge Device Prediction Function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import json\n",
    "\n",
    "class WeatherPredictor:\n",
    "    def __init__(self, model_path, config_path):\n",
    "        # Load TFLite model\n",
    "        self.interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "        \n",
    "        self.input_details = self.interpreter.get_input_details()\n",
    "        self.output_details = self.interpreter.get_output_details()\n",
    "        \n",
    "        # Load configuration\n",
    "        with open(config_path, 'r') as f:\n",
    "            self.config = json.load(f)\n",
    "        \n",
    "        self.scale_values = np.array(self.config['preprocessing']['scale_values'])\n",
    "        self.min_values = np.array(self.config['preprocessing']['min_values'])\n",
    "    \n",
    "    def normalize_input(self, data):\n",
    "        \"\"\"Normalize input data using saved scaler parameters\"\"\"\n",
    "        return (data - self.min_values) / self.scale_values\n",
    "    \n",
    "    def denormalize_output(self, data):\n",
    "        \"\"\"Denormalize output predictions\"\"\"\n",
    "        # Only denormalize the first 4 features (weather targets)\n",
    "        scale_subset = self.scale_values[:4]\n",
    "        min_subset = self.min_values[:4]\n",
    "        return (data * scale_subset) + min_subset\n",
    "    \n",
    "    def predict(self, weather_sequence):\n",
    "        \"\"\"\n",
    "        Predict next day weather\n",
    "        weather_sequence: array of shape (30, 6) with last 30 days of weather data\n",
    "        Returns: [precipitation, avg_temp, max_temp, min_temp] for next day\n",
    "        \"\"\"\n",
    "        # Normalize input\n",
    "        normalized_input = self.normalize_input(weather_sequence)\n",
    "        \n",
    "        # Reshape for model input\n",
    "        input_data = normalized_input.reshape(1, 30, 6).astype(np.float32)\n",
    "        \n",
    "        # Run prediction\n",
    "        self.interpreter.set_tensor(self.input_details[0]['index'], input_data)\n",
    "        self.interpreter.invoke()\n",
    "        output_data = self.interpreter.get_tensor(self.output_details[0]['index'])\n",
    "        \n",
    "        # Denormalize output\n",
    "        prediction = self.denormalize_output(output_data[0])\n",
    "        \n",
    "        return {\n",
    "            'precipitation': float(prediction[0]),\n",
    "            'avg_temperature': float(prediction[1]),\n",
    "            'max_temperature': float(prediction[2]),\n",
    "            'min_temperature': float(prediction[3])\n",
    "        }\n",
    "\n",
    "# Example usage:\n",
    "# predictor = WeatherPredictor('weather_prediction_model.tflite', 'model_config.json')\n",
    "# result = predictor.predict(last_30_days_data)\n",
    "'''\n",
    "\n",
    "with open('edge_predictor.py', 'w') as f:\n",
    "    f.write(edge_prediction_code)\n",
    "\n",
    "print(\"üìÅ edge_predictor.py - Ready-to-use prediction class for edge devices\")\n",
    "\n",
    "print(\"\\nüéØ Model Training Complete!\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Your weather prediction model is ready for deployment!\")\n",
    "print(\"Transfer these files to your edge device:\")\n",
    "print(\"  ‚Ä¢ weather_prediction_model.tflite\")\n",
    "print(\"  ‚Ä¢ model_config.json\") \n",
    "print(\"  ‚Ä¢ edge_predictor.py\")\n",
    "print(\"\\nThe model can predict tomorrow's weather based on the last 30 days of data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2dc212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
